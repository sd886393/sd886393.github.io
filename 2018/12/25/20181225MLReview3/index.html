<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>七天算法梳理之决策树 | littleji</title>
  <meta name="author" content="littleji">
  
  <meta name="description" content="littleji&#39;s blog">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="七天算法梳理之决策树"/>
  <meta property="og:site_name" content="littleji"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="littleji" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-77530561-1', 'auto');
	ga('send', 'pageview');

</script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-127734909-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-127734909-1');
</script>


<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet">
  <h1><a href="/">littleji</a></h1>
  <h2><a href="/">a blog</a></h2>
  <h2><a href="https://github.com/littleji" title="GithubID:littleji" target="_blank"><i class="fa fa-3x fa-github"></i></a> &nbsp;</h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">About</a></li>
    
      <li><a href="/booklist">Booklist</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
    
    <div id="toc" class="toc-article">
      <strong class="toc-title">目录</strong>
      <a class="js-toggle-toc" href="javascript:void(0)"></a>
      <div class="toc-content">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E8%AE%BA%E5%9F%BA%E7%A1%80"><span class="toc-number">1.</span> <span class="toc-text">信息论基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%86%B5"><span class="toc-number">1.1.</span> <span class="toc-text">熵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%94%E5%90%88%E7%86%B5"><span class="toc-number">1.2.</span> <span class="toc-text">联合熵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E7%86%B5"><span class="toc-number">1.3.</span> <span class="toc-text">条件熵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A"><span class="toc-number">1.4.</span> <span class="toc-text">信息增益</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E5%B0%BC%E4%B8%8D%E7%BA%AF%E5%BA%A6"><span class="toc-number">1.5.</span> <span class="toc-text">基尼不纯度</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%B8%8D%E5%90%8C%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">决策树的不同分类算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#ID3%E7%AE%97%E6%B3%95"><span class="toc-number">2.1.</span> <span class="toc-text">ID3算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#C4-5"><span class="toc-number">2.2.</span> <span class="toc-text">C4.5</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%9E%E5%BD%92%E6%A0%91%E5%8E%9F%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">回归树原理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#CART%E5%88%86%E7%B1%BB%E6%A0%91"><span class="toc-number">3.1.</span> <span class="toc-text">CART分类树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CART%E7%9A%84%E7%94%9F%E6%88%90"><span class="toc-number">3.1.1.</span> <span class="toc-text">CART的生成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CART%E7%9A%84%E5%89%AA%E6%9E%9D"><span class="toc-number">3.1.2.</span> <span class="toc-text">CART的剪枝</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88%E6%89%8B%E6%AE%B5"><span class="toc-number">4.</span> <span class="toc-text">决策树防止过拟合手段</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0"><span class="toc-number">5.</span> <span class="toc-text">模型评估</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#python%E5%8F%AF%E8%A7%86%E5%8C%96%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E5%AF%B9%E5%BA%94%E7%9A%84%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0"><span class="toc-number">6.</span> <span class="toc-text">python可视化决策树与对应的函数实现</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">7.</span> <span class="toc-text">参考</span></a></li></ol>
      </div>
    </div>
  
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2018-12-24T16:00:00.000Z"><a href="/2018/12/25/20181225MLReview3/">2018-12-25</a></time>
      
      
  
    <h1 class="title">七天算法梳理之决策树</h1>
  

    </header>
    <div class="entry">
      
        <h1 id="信息论基础"><a href="#信息论基础" class="headerlink" title="信息论基础"></a>信息论基础</h1><p>信息论的基础由香农博士于1948年奠定.下面说明关于信息论的一些基本概念.</p>
<h2 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h2><p>上表示一个随机变量不确定的数量.如果一个随机变量的熵越大,那么其不确定也就越大.<br>如果$X$为离散型变量,取值为$\mathbb R$,其概率分布为$p(x)=P(X=x),x\in \mathbb R$,那么X的熵$H(X)$定义为:</p>
<script type="math/tex; mode=display">
H(X)=-\sum_{x \in R}p(x)log_2p(x)</script><h2 id="联合熵"><a href="#联合熵" class="headerlink" title="联合熵"></a>联合熵</h2><p>联合熵其实就是描述一对随机变量平均所需要的信息量.<br>如果$X,Y$是一对离散型随机变量 $X,Y ~ p(x,y),X,Y$的联合熵为$H(X,Y)$为:</p>
<script type="math/tex; mode=display">
H(X,Y)=-\sum_{x \in X}\sum_{y \in Y}p(x,y)logp(x,y)</script><h2 id="条件熵"><a href="#条件熵" class="headerlink" title="条件熵"></a>条件熵</h2><p>条件熵$H(Y|X)$的意思是,在X发生的条件下,Y的不确定性有</p>
<script type="math/tex; mode=display">
H(Y|X)=\sum_{x \in X}\sum_{y \in Y}p(x, y)logp(y | x)</script><p>将联合概率进行展开后发现:</p>
<script type="math/tex; mode=display">
H(X, Y)=-\sum_{x \in X}p(x)logp(x)-\sum_{x \in X}\sum_{y \in Y}p(x, y)logp(y | x) = H(X)+H(Y|X)</script><h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><p>现在有属性a, 其可能有v个可能的取值,如果使用属性a来对样本D进行划分的话,易知会产生v个节点,那么所有属性为$a_v$的样本可记为$D^v$.,这时候再根据各个节点对应所占的比例$|D^v|/|D|$分配权重,就可以知道使用属性a对D进行划分的时候所获得的信息增益,也就是说使用整个样本的信息熵,减去通过属性a划分的信息熵之和就是信息增益.</p>
<p>现在假设样本D的信息熵为</p>
<script type="math/tex; mode=display">
Ent(D)=-\sum_{k=1}^{|v|}p_klog_2p_k</script><p>那么信息增益为:</p>
<script type="math/tex; mode=display">
Gain(D,a)=Ent(D)-\sum_{v=1}^{V}\frac{|D^v|}{|D|}Ent(D^v)</script><h2 id="基尼不纯度"><a href="#基尼不纯度" class="headerlink" title="基尼不纯度"></a>基尼不纯度</h2><p>基尼不纯度是CART算法划分属性所使用的度量方法,其直观上的理解是从一个数据集D中任意抽取两个样本,其类别不一致的概率.其具体的公式如下:</p>
<script type="math/tex; mode=display">
Gini(D)=\sum_{k=1}{|y|}\sum_{k^{'}\neq k}(p_kp_k')</script><h1 id="决策树的不同分类算法"><a href="#决策树的不同分类算法" class="headerlink" title="决策树的不同分类算法"></a>决策树的不同分类算法</h1><h2 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h2><p>流程具体如下:</p>
<ol>
<li>首先考虑样本中只有一个类或者没有属性的情况</li>
<li>计算各个属性的信息增益后</li>
<li>选择信息增益最多的属性进行节点分类,建立各个节点分支</li>
<li>再依次的再各个节点中进行选择计算信息增益,返回步骤2重复迭代</li>
<li>到达指定的退出条件,没有特征或者信息增益较小<br>由于ID3 算法只有生成树的过程,没有剪枝等过程,所以可能过拟合.</li>
</ol>
<h2 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h2><p>首先,信息增益比的定义是信息增益G(D,a)与训练数据集熵H(D)的比</p>
<script type="math/tex; mode=display">
g_R(D,a)=\frac{g(D,a)}{H(D)}</script><p>该C4.5算法则是针对于ID3算法的改进,在生成树的过程中使用了信息增益比来选择,而不是单纯的使用信息增益<br>算法过程如下:<br>假设 数据集D 特征集A 阀值ε</p>
<ol>
<li>如果数据中均为同一个类,则返回,算法结束</li>
<li>如果 $A=\varnothing$, 则返回一个单节点的树,并选择实例数最多的类,为该节点的类别,算法结束</li>
<li>选择其中信息增益比最大的节点</li>
<li>再依次选择各个节点,计算当前节点的内的信息增益比,进行迭代</li>
<li>最终达到指定的退出条件,即信息增益比过低,或者没有更多的特征时退出算法</li>
</ol>
<p>上面的构建的节点树都是分类树,只不过节点划分的方式不同.那么什么是回归树呢?</p>
<h1 id="回归树原理"><a href="#回归树原理" class="headerlink" title="回归树原理"></a>回归树原理</h1><p>回归树对于样本的划分,通过遍历所有输入变量，找到最优的切分变量j和最优的切分点s，即选择第j个特征$x^j$和它的取值s将输入空间划分为两部分，然后重复这个操作,对于连续性的样本值非常有效.<br>具体算法如下</p>
<ol>
<li>选择最优的切分变量j和最优的切分点s，求解 <script type="math/tex; mode=display">
min_{j,s}[min_{c_{1}}\sum_{x_{i}\in R_{1}(j,s)}(y_{i}-c_{1})^2+min_{c_{2}}\sum_{x_{i}\in R_{2}(j,s)}(y_{i}-c_{2})^2]</script></li>
<li>遍历所有特征，对固定的特征扫描所有取值，找到使上式达到最小值的对(j,s).</li>
<li>用选定的对 (j,s)划分区域，并确定该区域的预测值；</li>
<li>继续对两个字区域调用上述步骤，直至满足停止条件；</li>
</ol>
<h2 id="CART分类树"><a href="#CART分类树" class="headerlink" title="CART分类树"></a>CART分类树</h2><p>CART分类树的全称是分类与回归树,主要的原理思想是将内部的节点特征取值为”是”或”否”两个值,左分支为是,右分支为否,这样整个决策树就可以在整个样本空间中求取对应的条件概率分布.<br>算法由特征选择和生成树以及前面两种算法所没有的剪枝构成,算法主要包括两个部分:树的生成与剪枝</p>
<h3 id="CART的生成"><a href="#CART的生成" class="headerlink" title="CART的生成"></a>CART的生成</h3><p>从根节点开始，对节点计算现有特征的基尼指数，对每一个特征，例如AA，再对其每个可能的取值如aa,根据样本点对A=aA=a的结果的”是“与”否“划分为两个部分，利用</p>
<script type="math/tex; mode=display">
Gini(D,A=a)=\frac{|D_{1}|}{|D|}Gini(D_{1})+\frac{|D_{2}|}{|D|}Gini(D_{2})</script><p>进行计算；在所有可能的特征AA以及该特征所有的可能取值a中，选择基尼指数最小的特征及其对应的取值作为最优特征和最优切分点。然后根据最优特征和最优切分点，将本节点的数据集二分，生成两个子节点<br>对两个字节点递归地调用上述步骤，直至节点中的样本个数小于阈值，或者样本集的基尼指数小于阈值，或者没有更多特征后停止；</p>
<h3 id="CART的剪枝"><a href="#CART的剪枝" class="headerlink" title="CART的剪枝"></a>CART的剪枝</h3><p>剪枝就是对生成的树进行裁剪简化的过程,其一般是通过极小化决策树整体的损失函数或代价函数来实现.<br>CART的剪枝是通过两个步骤:</p>
<ol>
<li>从树的底部不断地剪枝直到根节点,形成对应的子树序列</li>
<li>通过交叉验证法,对子树的序列进行测试,并从中选取最优的子树</li>
</ol>
<h1 id="决策树防止过拟合手段"><a href="#决策树防止过拟合手段" class="headerlink" title="决策树防止过拟合手段"></a>决策树防止过拟合手段</h1><p>决策树过拟合主要有两个手段,分别为early stopping与剪枝.</p>
<ol>
<li>earlystopping:限制选取的分类节点的总数,树的深度,节点中的实例数,阈值等</li>
<li>剪枝,即当前节点的划分无法带来决策树泛化性能的提升,增删除对应的节点</li>
</ol>
<h1 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h1><p>可以使用之前梳理的AUC ROC 交叉验证 随机抽样等方法,这里就不再赘述了.</p>
<h1 id="python可视化决策树与对应的函数实现"><a href="#python可视化决策树与对应的函数实现" class="headerlink" title="python可视化决策树与对应的函数实现"></a>python可视化决策树与对应的函数实现</h1><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">import pydotplus</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn import tree</span><br><span class="line">import collections</span><br><span class="line"># Data Collection</span><br><span class="line">X = [ [180, 15,0],     </span><br><span class="line">      [177, 42,0],</span><br><span class="line">      [136, 35,1],</span><br><span class="line">      [174, 65,0],</span><br><span class="line">      [141, 28,1]]</span><br><span class="line"></span><br><span class="line">Y = ['man', 'woman', 'woman', 'man', 'woman']    </span><br><span class="line"></span><br><span class="line">data_feature_names = [ 'height', 'hair length', 'voice pitch' ]</span><br><span class="line"># Training</span><br><span class="line">clf = tree.DecisionTreeClassifier()</span><br><span class="line">clf = clf.fit(X,Y)</span><br><span class="line"># Visualize data</span><br><span class="line">dot_data = tree.export_graphviz(clf,</span><br><span class="line">                                feature_names=data_feature_names,</span><br><span class="line">                                out_file=None,</span><br><span class="line">                                filled=True,</span><br><span class="line">                                rounded=True)</span><br><span class="line">graph = pydotplus.graph_from_dot_data(dot_data)</span><br><span class="line"></span><br><span class="line">colors = ('turquoise', 'orange')</span><br><span class="line">edges = collections.defaultdict(list)</span><br><span class="line"></span><br><span class="line">for edge in graph.get_edge_list():</span><br><span class="line">    edges[edge.get_source()].append(int(edge.get_destination()))</span><br><span class="line"></span><br><span class="line">for edge in edges:</span><br><span class="line">    edges[edge].sort()    </span><br><span class="line">    for i in range(2):</span><br><span class="line">        dest = graph.get_node(str(edges[edge][i]))[0]</span><br><span class="line">        dest.set_fillcolor(colors[i])</span><br><span class="line"></span><br><span class="line">graph.write_png('tree.png')</span><br></pre></td></tr></tbody></table></figure>
<p>主要的函数为</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href>统计自然语言处理-宗成庆</a><br><a href>机器学习-周志华</a><br><a href>统计学习方法-李航</a><br><a href="https://blog.csdn.net/weixin_36586536/article/details/80468426" target="_blank" rel="noopener">决策树(分类树、回归树</a><br><a href="https://pythonprogramminglanguage.com/decision-tree-visual-example/" target="_blank" rel="noopener">Decision tree visual example</a></p>
<hr>
<p>版权声明:本文由littleji.com创作并发表,转载请注明作者及出处,欢迎关注公众号:littleji_com<br><a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener">本文遵守CC BY0SA 4.0</a><br>if you have any questions, please leave a message behind or give an <a href="https://github.com/littleji/littleji.github.io/issues" target="_blank" rel="noopener">issue</a></p>
<p>本文链接为：<a href="https://blog.littleji.com/2018/12/25/20181225MLReview3/">https://blog.littleji.com/2018/12/25/20181225MLReview3/</a></p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/2018-12/">2018-12</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/MachineLearning/">MachineLearning</a>
  </div>

        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">留言</h1>
  
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
  
</section>


</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//baidu.com" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:blog.littleji.com">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">分类</h3>
  <ul class="entry">
  
    <li><a href="/categories/2019-04/">2019-04</a><small>1</small></li>
  
    <li><a href="/categories/2019-03/">2019-03</a><small>3</small></li>
  
    <li><a href="/categories/2019-02/">2019-02</a><small>2</small></li>
  
    <li><a href="/categories/2018-12/">2018-12</a><small>3</small></li>
  
    <li><a href="/categories/2018-11/">2018-11</a><small>1</small></li>
  
    <li><a href="/categories/2018-10/">2018-10</a><small>3</small></li>
  
    <li><a href="/categories/2018-09/">2018-09</a><small>2</small></li>
  
    <li><a href="/categories/2018-02/">2018-02</a><small>1</small></li>
  
    <li><a href="/categories/2018-01/">2018-01</a><small>2</small></li>
  
    <li><a href="/categories/2017-05/">2017-05</a><small>1</small></li>
  
    <li><a href="/categories/2016-12/">2016-12</a><small>4</small></li>
  
    <li><a href="/categories/2016-11/">2016-11</a><small>4</small></li>
  
    <li><a href="/categories/2016-05/">2016-05</a><small>2</small></li>
  
    <li><a href="/categories/2016-04/">2016-04</a><small>1</small></li>
  
  </ul>
</div>



  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/Algorithm/">Algorithm</a><small>1</small></li>
  
    <li><a href="/tags/BookList/">BookList</a><small>1</small></li>
  
    <li><a href="/tags/DataMining/">DataMining</a><small>1</small></li>
  
    <li><a href="/tags/DataStructure/">DataStructure</a><small>1</small></li>
  
    <li><a href="/tags/DistributedComputation/">DistributedComputation</a><small>3</small></li>
  
    <li><a href="/tags/ELK/">ELK</a><small>3</small></li>
  
    <li><a href="/tags/ElasticSearch/">ElasticSearch</a><small>2</small></li>
  
    <li><a href="/tags/Error/">Error</a><small>1</small></li>
  
    <li><a href="/tags/Git/">Git</a><small>1</small></li>
  
    <li><a href="/tags/Golang/">Golang</a><small>1</small></li>
  
    <li><a href="/tags/Graph/">Graph</a><small>1</small></li>
  
    <li><a href="/tags/Java/">Java</a><small>2</small></li>
  
    <li><a href="/tags/Linux/">Linux</a><small>2</small></li>
  
    <li><a href="/tags/Logstash/">Logstash</a><small>2</small></li>
  
    <li><a href="/tags/MachineLearning/">MachineLearning</a><small>5</small></li>
  
    <li><a href="/tags/MySQL/">MySQL</a><small>1</small></li>
  
    <li><a href="/tags/Mybatis/">Mybatis</a><small>1</small></li>
  
    <li><a href="/tags/NLP/">NLP</a><small>6</small></li>
  
    <li><a href="/tags/Navicat/">Navicat</a><small>1</small></li>
  
    <li><a href="/tags/ORM/">ORM</a><small>1</small></li>
  
    <li><a href="/tags/Programmer/">Programmer</a><small>1</small></li>
  
    <li><a href="/tags/Programming/">Programming</a><small>5</small></li>
  
    <li><a href="/tags/Rpc/">Rpc</a><small>2</small></li>
  
    <li><a href="/tags/Security/">Security</a><small>1</small></li>
  
    <li><a href="/tags/SiteManagement/">SiteManagement</a><small>1</small></li>
  
    <li><a href="/tags/SoftwareEngineering/">SoftwareEngineering</a><small>3</small></li>
  
    <li><a href="/tags/Translate/">Translate</a><small>2</small></li>
  
    <li><a href="/tags/jsonrpc4j/">jsonrpc4j</a><small>2</small></li>
  
    <li><a href="/tags/life/">life</a><small>1</small></li>
  
    <li><a href="/tags/信息安全/">信息安全</a><small>1</small></li>
  
    <li><a href="/tags/区块链/">区块链</a><small>1</small></li>
  
    <li><a href="/tags/图/">图</a><small>1</small></li>
  
    <li><a href="/tags/思考/">思考</a><small>1</small></li>
  
    <li><a href="/tags/数据挖掘/">数据挖掘</a><small>1</small></li>
  
    <li><a href="/tags/数据结构/">数据结构</a><small>1</small></li>
  
    <li><a href="/tags/框架/">框架</a><small>1</small></li>
  
    <li><a href="/tags/算法/">算法</a><small>1</small></li>
  
    <li><a href="/tags/自然语言处理/">自然语言处理</a><small>1</small></li>
  
    <li><a href="/tags/计算机语言/">计算机语言</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">最新文章</h3>
  <ul class="entry">
    
      <li>
        <a href="/2019/04/27/20190427SomethingBeforeTheNlpPipline/">实施NLP流水线之前干点什么</a>
      </li>
    
      <li>
        <a href="/2019/03/15/20190318HeadFirstForGitLab/">Gitlab 入门与 工作流</a>
      </li>
    
      <li>
        <a href="/2019/03/05/20190305DataWhaleNLPTask2/">常见的分词方法与文本向量化</a>
      </li>
    
      <li>
        <a href="/2019/03/03/20190303DataWhaleNLPTask1/">windows下TensorFlow安装与imdb文本分类</a>
      </li>
    
      <li>
        <a href="/2019/02/19/20190219HandoverMemoList/">软件项目交接清单</a>
      </li>
    
  </ul>
</div>


  
<div class="widget links">
  <h3 class="title">友链</h3>
  <ul class="entry">
    
      <li><a target="_blank" rel="noopener" href="http://www.xiaobaidonghui.cn">小白</a></li>
    
  </ul>
</div>


</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2021 littleji
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'littleji';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
